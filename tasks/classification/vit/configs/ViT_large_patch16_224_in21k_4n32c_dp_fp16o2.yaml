# global configs
Global:
  checkpoint: null
  pretrained_model: null
  output_dir: ./output/
  device: gpu
  save_interval: 1
  max_num_latest_checkpoint: 0
  eval_during_train: True
  eval_interval: 1
  eval_unit: "epoch"
  accum_steps: 1
  epochs: 90
  print_batch_step: 10
  use_visualdl: False
  seed: 2021

# FP16 setting
FP16:
  level: O2
  GradScaler:
    init_loss_scaling: 65536.0

DistributedStrategy:
  data_parallel: True

# model architecture
Model:
  name: ViT_large_patch16_224
  class_num: 21841
  drop_rate: 0.1

# loss function config for traing/eval process
Loss:
  Train:
    - ViTCELoss:
        weight: 1.0
        epsilon: 0.0001
  Eval:
    - CELoss:
        weight: 1.0

LRScheduler:
  name: ViTLRScheduler
  learning_rate: 1e-3
  decay_type: linear
  warmup_steps: 10000

Optimizer:
  name: AdamW
  betas: (0.9, 0.999)
  epsilon: 1e-6
  weight_decay: 0.15
  exp_avg_force_fp32: True

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: ImageNetDataset
      image_root: ./dataset/ImageNet21K/
      multi_label: True
      class_num: 21841
      cls_label_path: ./dataset/ImageNet21K/image_all_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
            interpolation: bicubic
            backend: pil
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: ''
        - ToCHWImage:
    sampler:
      name: DistributedBatchSampler
      batch_size: 128
      drop_last: True
      shuffle: True
    loader:
      num_workers: 8
      use_shared_memory: True

  Eval:
    dataset:
      name: ImageNetDataset
      image_root: ./dataset/ImageNet21K/
      cls_label_path: ./dataset/ImageNet21K/image_dummy_val_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            resize_short: 256
            interpolation: bicubic
            backend: pil
        - CenterCropImage:
            size: 224
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: ''
        - ToCHWImage:

    sampler:
      name: DistributedBatchSampler
      batch_size: 256
      drop_last: False
      shuffle: False
    loader:
      num_workers: 8
      use_shared_memory: True

Metric:
  Eval:
    - TopkAcc:
        topk: [1, 5]

Export:
  export_type: paddle
  input_shape: [None, 3, 224, 224]
